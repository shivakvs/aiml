{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e136cbe-50d3-48b3-aea0-9b2aa6253ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import  train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_curve,roc_auc_score, auc, precision_score, recall_score, f1_score,matthews_corrcoef\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "135b149d-cae4-4f0f-bacf-8d7f2d1e8004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n",
      "None\n",
      "Records  569  Cols  33\n"
     ]
    }
   ],
   "source": [
    "# Dataset : Breast Cancer Wisconsin (Diagnostic) Data Set\n",
    "# Dataset URL : https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data\n",
    "ds = pd.read_csv(\"data.csv\")\n",
    "print(ds.info())\n",
    "\n",
    "# Rows, cols\n",
    "print(\"Records \",ds.shape[0], \" Cols \",ds.shape[1])\n",
    "\n",
    "# remove empty contents \n",
    "ds = ds.drop(['id','Unnamed: 32'],axis=1)\n",
    "ds.isna().sum()\n",
    "ds.dropna()\n",
    "\n",
    "# Features and target\n",
    "X = ds.drop(columns=[\"diagnosis\"])\n",
    "\n",
    "y = ds[\"diagnosis\"]\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y = pd.Series(le.fit_transform(y), name=\"diagnosis\") \n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42, stratify=y )\n",
    "\n",
    "# Combine test features and labels\n",
    "test_df = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# Save test data to file\n",
    "test_df.to_csv(\"test_data.csv\", index=False)\n",
    "\n",
    "# Dictionary result will be stored. This result shall be used in streamlit\n",
    "result = { }\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)   \n",
    "\n",
    "def do_evaluation_metrics(y_test, y_pred):\n",
    "    # Dictionary \n",
    "    metrics = {}\n",
    "   \n",
    "    # Accuracy\n",
    "    metrics[\"accuracy\"] = accuracy_score(y_test,y_pred)\n",
    "    # AUC Score\n",
    "    metrics[\"auc_score\"] =  roc_auc_score(y_test,y_pred)\n",
    "    # Precision\n",
    "    metrics[\"precision\"] = precision_score(y_test,y_pred, average='binary')\n",
    "    # Recall\n",
    "    metrics[\"recall\"] = recall_score(y_test,y_pred, average='binary')\n",
    "    #f1 score\n",
    "    metrics[\"f1_score_result\"] = f1_score(y_test,y_pred)\n",
    "    # MCC Score\n",
    "    metrics[\"mcc_score\"] = matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def do_print_metrics(dict):\n",
    "    print(f\"    Accuracy  |     AUC     |    Precision  |    Recall  |    F1    |    MCC   | \")\n",
    "    print(f\"{dict[\"accuracy\"]:.4f}    |   {dict[\"auc_score\"]:.4f} | {dict[\"precision\"]:.4f}  | {dict[\"recall\"]:.4f} | {dict[\"f1_score_result\"]:.4f} |  {dict[\"mcc_score\"]:.4f}   |\")\n",
    "    pass  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd8e5f0f-aa00-47e7-9668-d4331e231634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_logistics_regression_model(X_train_scaled,y_train,X_test,y_test):\n",
    "    # Input params : \n",
    "    #  X_train and y_train - Train Data\n",
    "    #  X_test and y_test - Test data\n",
    "    \n",
    "    # Model\n",
    "    lg = LogisticRegression(max_iter=10000, class_weight='balanced')\n",
    "    lg.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = lg.predict(X_test_scaled)\n",
    "\n",
    "    result = do_evaluation_metrics(y_test, y_pred) \n",
    "    result[\"model\"] = lg\n",
    "    result['name'] = \"Logistic Regression\"\n",
    "    result['y_test'] = y_test\n",
    "    result['y_pred'] = y_pred\n",
    "    \n",
    "    pickle.dump(result, open(\"logistic_model.pkl\", \"wb\"))\n",
    "    # Evaluation metrics\n",
    "    return result\n",
    "\n",
    "def build_decision_tree_classifier_model(X_train_scaled,y_train,X_test,y_test):\n",
    "    # Input params : \n",
    "    #  X_train and y_train - Train Data\n",
    "    #  X_test and y_test - Test data\n",
    "\n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        'max_depth': [3,5,7,10],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1,2, 4,8]\n",
    "    }\n",
    "\n",
    "    model = DecisionTreeClassifier(  max_depth=None, random_state=42 )\n",
    "    # GridSearch\n",
    "    grid = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring='f1',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid.best_estimator_\n",
    "    accuracy = best_model.score(X_test, y_test)\n",
    "    # Predict    \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Evaluation metrics\n",
    "    result  = do_evaluation_metrics(y_test, y_pred)\n",
    "    result['accuracy'] = accuracy\n",
    "    result[\"auc_score\"] =  roc_auc_score(y_test, y_prob)\n",
    "    result['model'] = best_model\n",
    "    result['name'] = \"Decision Tree\"\n",
    "\n",
    "    result['y_test'] = y_test\n",
    "    result['y_pred'] = y_pred\n",
    "    \n",
    "    # print(result)\n",
    "    pickle.dump(result, open(\"decision_tree_model.pkl\", \"wb\"))\n",
    "    return result\n",
    "    \n",
    "def build_KNN_classifier_model(X_train_scaled,y_train,X_test,y_test):\n",
    "    # Input params : \n",
    "    #  X_train and y_train - Train Data\n",
    "    #  X_test and y_test - Test data\n",
    "\n",
    "    # Train model\n",
    "    model = KNeighborsClassifier(n_neighbors=3)    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "  \n",
    "    # Evaluation metrics\n",
    "    dict =  do_evaluation_metrics(y_test, y_pred)\n",
    "    dict['name'] =\"KNN\"\n",
    "    dict['model'] = model\n",
    "    dict['y_test'] = y_test\n",
    "    dict['y_pred'] = y_pred\n",
    "    \n",
    "\n",
    "    pickle.dump(dict, open(\"KNN_classifier.pkl\", \"wb\"))\n",
    "    \n",
    "    return dict;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce97da81-307c-4091-9d3a-0ce679aeace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_NBGaussion_model(X_train_scaled,y_train,X_test,y_test):\n",
    "    # Input params : \n",
    "    #  X_train and y_train - Train Data\n",
    "    #  X_test and y_test - Test data\n",
    "\n",
    "    # Train model\n",
    "    model = GaussianNB()    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    dict = do_evaluation_metrics(y_test, y_pred)\n",
    "    dict['name'] = \"Naive Bayes\"\n",
    "    dict['model'] = model\n",
    "    dict['y_test'] = y_test\n",
    "    dict['y_pred'] = y_pred\n",
    "    \n",
    "    pickle.dump(dict, open(\"Naive_bayes_Gaussian_model.pkl\", \"wb\"))\n",
    "    \n",
    "    return dict\n",
    "\n",
    "def build_random_forest_classifier_model(X_train_scaled,y_train,X_test,y_test):\n",
    "    # Input params : \n",
    "    #  X_train and y_train - Train Data\n",
    "    #  X_test and y_test - Test data\n",
    "\n",
    "    # Define parameter grid\n",
    "    params_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 5, 10],\n",
    "        'min_samples_split': [2, 5]\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42,class_weight='balanced')\n",
    "    # GridSearch\n",
    "    grid = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=params_grid,\n",
    "        cv=5,\n",
    "        scoring='recall',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid.best_estimator_\n",
    "    accuracy = best_model.score(X_test, y_test)\n",
    "    \n",
    "    # Predict    \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Evaluation metrics\n",
    "    dict  = do_evaluation_metrics(y_test, y_pred)\n",
    "    dict['accuracy'] = accuracy\n",
    "    dict['model'] = best_model\n",
    "    dict[\"auc_score\"] =  roc_auc_score(y_test, y_prob)\n",
    "    dict['name'] = \"Random Forest\"\n",
    "    dict['y_test'] = y_test\n",
    "    dict['y_pred'] = y_pred\n",
    "    \n",
    "    # For streamlit app, export this model \n",
    "    pickle.dump(dict, open(\"random_forest_model.pkl\", \"wb\"))\n",
    "    \n",
    "    return dict\n",
    "\n",
    "def build_XGBoost_model(X_train_scaled,y_train,X_test,y_test):\n",
    "    # Input params : \n",
    "    #  X_train and y_train - Train Data\n",
    "    #  X_test and y_test - Test data\n",
    "\n",
    "    # Train model\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        random_state=42,        \n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    dict = do_evaluation_metrics(y_test, y_pred)   \n",
    "    dict['name'] = \"XGBoost Classifier\"\n",
    "    dict['model'] = model\n",
    "\n",
    "    dict['y_test'] = y_test\n",
    "    dict['y_pred'] = y_pred\n",
    "    \n",
    "    # For streamlit app, export this model \n",
    "    pickle.dump(dict, open(\"XGB_classifier_model.pkl\", \"wb\"))\n",
    "  \n",
    "    return dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2e5d131-a43f-4067-ab82-037ea0ad97e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "dict_lg_score = build_logistics_regression_model(X_train_scaled, y_train, X_test, y_test)\n",
    "result['LG'] = dict_lg_score\n",
    "\n",
    "# Decision Tree\n",
    "dict_dt_score = build_decision_tree_classifier_model(X_train_scaled, y_train, X_test, y_test)\n",
    "result['DT'] = dict_dt_score\n",
    "\n",
    "\n",
    "# print(\"KNN Classifier Model \")\n",
    "# KNN Classifier\n",
    "dict_knn_score = build_KNN_classifier_model(X_train_scaled, y_train, X_test, y_test)\n",
    "result['KNN'] = dict_knn_score\n",
    "\n",
    "# Naive Bayes Gaussian Classifier\n",
    "dict_nbg_score = build_NBGaussion_model(X_train_scaled, y_train, X_test, y_test)\n",
    "result['NBG'] = dict_nbg_score\n",
    "\n",
    "# Random Forest\n",
    "dict_rf_score = build_random_forest_classifier_model(X_train_scaled, y_train, X_test, y_test)\n",
    "result['RF'] = dict_rf_score\n",
    "\n",
    "# XGBoost\n",
    "dict_xgb_score = build_XGBoost_model(X_train_scaled, y_train, X_test, y_test)\n",
    "result['XGB'] = dict_xgb_score\n",
    "\n",
    "print (\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f13c1719-89bd-43a5-a5cb-1179b781966f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML Model Name           Accuracy       AUC    Precision    Recall        F1       MCC\n",
      "--------------------  ----------  --------  -----------  --------  --------  --------\n",
      "Logistics Regression    0.973684  0.969246     0.97561   0.952381  0.963855  0.94334\n",
      "Decision Tree           0.938596  0.922454     0.948718  0.880952  0.91358   0.867493\n",
      "KNN                     0.938596  0.921627     0.972973  0.857143  0.911392  0.868766\n",
      "Naive Bayes             0.921053  0.907738     0.923077  0.857143  0.888889  0.829162\n",
      "Random Forest           0.973684  0.997354     1         0.928571  0.962963  0.944155\n",
      "XGBoost                 0.964912  0.952381     1         0.904762  0.95      0.92582\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "print(tabulate(\n",
    "    [\n",
    "        ['Logistics Regression',dict_lg_score[\"accuracy\"],dict_lg_score[\"auc_score\"],dict_lg_score[\"precision\"], dict_lg_score[\"recall\"],dict_lg_score[\"f1_score_result\"],dict_lg_score[\"mcc_score\"]], \n",
    "        ['Decision Tree',dict_dt_score[\"accuracy\"],dict_dt_score[\"auc_score\"],dict_dt_score[\"precision\"], dict_dt_score[\"recall\"],dict_dt_score[\"f1_score_result\"],dict_dt_score[\"mcc_score\"]],\n",
    "        ['KNN',dict_knn_score[\"accuracy\"],dict_knn_score[\"auc_score\"],dict_knn_score[\"precision\"], dict_knn_score[\"recall\"],dict_knn_score[\"f1_score_result\"],dict_knn_score[\"mcc_score\"]],\n",
    "        ['Naive Bayes',dict_nbg_score[\"accuracy\"],dict_nbg_score[\"auc_score\"],dict_nbg_score[\"precision\"], dict_nbg_score[\"recall\"],dict_nbg_score[\"f1_score_result\"],dict_nbg_score[\"mcc_score\"]],\n",
    "        ['Random Forest',dict_rf_score[\"accuracy\"],dict_rf_score[\"auc_score\"],dict_rf_score[\"precision\"], dict_rf_score[\"recall\"],dict_rf_score[\"f1_score_result\"],dict_rf_score[\"mcc_score\"]],\n",
    "        ['XGBoost',dict_xgb_score[\"accuracy\"],dict_xgb_score[\"auc_score\"],dict_xgb_score[\"precision\"], dict_xgb_score[\"recall\"],dict_xgb_score[\"f1_score_result\"],dict_xgb_score[\"mcc_score\"]]\n",
    "    ],\n",
    "    headers=['ML Model Name', 'Accuracy','AUC','Precision','Recall','F1','MCC']\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
