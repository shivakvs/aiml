import pandas as pd
import numpy as np
from sklearn.model_selection import  train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score,matthews_corrcoef
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from xgboost import XGBClassifier

# Loading dataset. Ref URL : 
ds = pd.read_csv("data.csv")
# print(ds.info())
# print(ds.head(5))

# Rows, cols
print("Records ",ds.shape[0], " Cols ",ds.shape[1])

# remove empty contents 
ds = ds.drop(['id','Unnamed: 32'],axis=1)
ds.isna().sum()

ds.dropna()

# Features and target
X = ds.drop(columns=["diagnosis"])
y = ds["diagnosis"]

# Encode labels
le = LabelEncoder()
y = le.fit_transform(y)

# Split
X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42, stratify=y )

# Scale
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)   

def do_evaluation_metrics(y_test, y_pred):
    # Dictionary 
    metrics = {}
    # Accuracy
    metrics["accuracy"] = accuracy_score(y_test,y_pred)
    # AUC Score
    metrics["auc_score"] = roc_auc_score(y_test, y_pred)
    # Precision
    metrics["precision"] = precision_score(y_test,y_pred, average='macro')
    # Recall
    metrics["recall"] = recall_score(y_test,y_pred, average='weighted')
    #f1 score
    metrics["f1_score_result"] = f1_score(y_test,y_pred,average='weighted')
    # MCC Score
    metrics["mcc_score"] = matthews_corrcoef(y_test, y_pred)
    
    return metrics

def do_print_metrics(dict):
    print(f"Accuracy    : {dict["accuracy"]:.4f}")
    print(f"AUC         : {dict["auc_score"]:.4f}")
    print(f"Precision   : {dict["precision"]:.4f}")
    print(f"Recall      : {dict["recall"]:.4f}")
    print(f"F1 Score    : {dict["f1_score_result"]:.4f}")
    print(f"MCC Score   : {dict["mcc_score"]:.4f}")
    pass  

def build_logistics_regression_model(X_train_scaled,y_train,X_test,y_test):
    # Input params : 
    #  X_train and y_train - Train Data
    #  X_test and y_test - Test data
    
    # Model
    clf = LogisticRegression(max_iter=10000, class_weight='balanced')
    clf.fit(X_train_scaled, y_train)
    
    # Predict
    y_pred = clf.predict(X_test_scaled)
    
    # Evaluation metrics
    return do_evaluation_metrics(y_test, y_pred)    

def build_decision_tree_classifier_model(X_train_scaled,y_train,X_test,y_test):
    # Input params : 
    #  X_train and y_train - Train Data
    #  X_test and y_test - Test data

    model = DecisionTreeClassifier(  max_depth=None, random_state=42 )
    model.fit(X_train_scaled, y_train)

    # Predict
    y_pred = model.predict(X_test_scaled)
    
    # Evaluation metrics
    return do_evaluation_metrics(y_test, y_pred)

def build_KNN_classifier_model(X_train_scaled,y_train,X_test,y_test):
    # Input params : 
    #  X_train and y_train - Train Data
    #  X_test and y_test - Test data

    # Train model
    model = KNeighborsClassifier(n_neighbors=3)    
    model.fit(X_train_scaled, y_train)

    # Predict
    y_pred = model.predict(X_test_scaled)
    
    # Evaluation metrics
    return do_evaluation_metrics(y_test, y_pred)

def build_NBGaussion_model(X_train_scaled,y_train,X_test,y_test):
    # Input params : 
    #  X_train and y_train - Train Data
    #  X_test and y_test - Test data

    # Train model
    model = GaussianNB()    
    model.fit(X_train_scaled, y_train)

    # Predict
    y_pred = model.predict(X_test_scaled)
    
    # Evaluation metrics
    return do_evaluation_metrics(y_test, y_pred)

def build_random_forest_classifier_model(X_train_scaled,y_train,X_test,y_test):
    # Input params : 
    #  X_train and y_train - Train Data
    #  X_test and y_test - Test data

    # Train model
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train_scaled, y_train)

    # Predict
    y_pred = model.predict(X_test_scaled)
    
    # Evaluation metrics
    return do_evaluation_metrics(y_test, y_pred)    

def build_XGBoost_model(X_train_scaled,y_train,X_test,y_test):
    # Input params : 
    #  X_train and y_train - Train Data
    #  X_test and y_test - Test data

    # Train model
    model = XGBClassifier(
        n_estimators=200,
        learning_rate=0.05,
        max_depth=4,
        random_state=42,        
        eval_metric='logloss'
    )
    
    model.fit(X_train_scaled, y_train)

    # Predict
    y_pred = model.predict(X_test_scaled)
    
    # Evaluation metrics
    return do_evaluation_metrics(y_test, y_pred)   

# Logistic Regression
dict_lg_score = build_logistics_regression_model(X_train_scaled, y_train, X_test, y_test)
print("Logistics Regression Model ")
do_print_metrics(dict_lg_score)

# Decision Tree
dict_dt_score = build_decision_tree_classifier_model(X_train_scaled, y_train, X_test, y_test)
print("Decision Tree Classifier Forest Model ")
do_print_metrics(dict_dt_score)

# KNN Classifier
dict_knn_score = build_KNN_classifier_model(X_train_scaled, y_train, X_test, y_test)
print("KNN Classifier Model ")
do_print_metrics(dict_knn_score)

# Naive Bayes Gaussian Classifier
dict_nbg_score = build_NBGaussion_model(X_train_scaled, y_train, X_test, y_test)
print("Naive Bayes Gaussian Model ")
do_print_metrics(dict_nbg_score)

# Random Forest
dict_rf_score = build_random_forest_classifier_model(X_train_scaled, y_train, X_test, y_test)
print("Random Forest Model ")
do_print_metrics(dict_rf_score)

# XGBoost
dict_xgb_score = build_XGBoost_model(X_train_scaled, y_train, X_test, y_test)
print("XGBoost Model ")
do_print_metrics(dict_xgb_score)





